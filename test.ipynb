{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03e8751-a89c-40ea-bbb5-60d5ef0a9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71cc5398-daff-49e1-8064-48f851460d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.170  Python-3.11.4 torch-2.0.1+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients\n",
      "\n",
      "image 1/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_315.jpg: 384x640 1 Swipe_machine, 4 Products, 93.1ms\n",
      "image 2/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_318.jpg: 384x640 1 Swipe_machine, 4 Products, 71.0ms\n",
      "image 3/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_319.jpg: 384x640 1 Swipe_machine, 4 Products, 1 Person, 72.0ms\n",
      "image 4/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_399.jpg: 384x640 1 Swipe_machine, 4 Products, 1 Person, 72.4ms\n",
      "image 5/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_400.jpg: 384x640 1 Swipe_machine, 4 Products, 1 Person, 81.4ms\n",
      "image 6/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_402.jpg: 384x640 1 Swipe_machine, 4 Products, 1 Person, 68.7ms\n",
      "image 7/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_403.jpg: 384x640 1 Swipe_machine, 4 Products, 1 Person, 69.0ms\n",
      "image 8/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_653.jpg: 384x640 1 Swipe_machine, 7 Products, 2 Persons, 1 Head, 102.4ms\n",
      "image 9/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_657.jpg: 384x640 1 Swipe_machine, 8 Products, 2 Persons, 2 Heads, 79.7ms\n",
      "image 10/10 C:\\Users\\prana\\Desktop\\Internship\\yolov8\\custom_dataset_1\\test\\Liverpool_cam04_630_Clip2_vk1_integrated_15_08_23_frame_659.jpg: 384x640 1 Swipe_machine, 8 Products, 2 Persons, 2 Heads, 81.3ms\n",
      "Speed: 2.2ms preprocess, 79.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=r'runs/detect/train2/weights/best.pt' source=r'custom_dataset_1/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6a71d-fcea-4678-a268-0f0061154813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
